{"cells":[{"cell_type":"markdown","metadata":{},"source":"<img src=\"mioti.png\" style=\"height: 100px\">\n<center style=\"color:#888\">Módulo Data Science in IoT<br/>Asignatura Deep Learning</center>\n# Worksheet S1: Introducción a TensorFlow"},{"cell_type":"markdown","metadata":{},"source":"## Objetivos\n\nEl objetivo de este worksheet es comprender el funcionamiento básico de TensorFlow, una libreria de código abierto desarrollada por Google que se utiliza en la gran mayoria de empresas y universidades de gran prestigio.\n\n## Introducción\n\nTensorFlow es una librería muy completa que nos permite trabajar en diferentes niveles de abstracción. En este worksheet vamos a ver las características básicas del Core de TensorFlow, es decir, del nivel más bajo que nos permite un control total sobre nuestros modelos. \n\n## Importing TensorFlow\n\nLo primero que tenemos que hacer para trabajar con tensorflow es importarlo. Esto permitirá a nuestra terminal python acceder a todas las clases, métodos y símbolos de TensorFlow. Normalmente se importa con el sobrenombre tf para hacer las instrucciones más cortas, de la siguiente forma:\n"},{"cell_type":"markdown","execution_count":9,"metadata":{},"outputs":[{"ename":"SyntaxError","evalue":"invalid syntax (<ipython-input-9-58751ca15d31>, line 1)","output_type":"error","traceback":["\u001b[1;36m  File \u001b[1;32m\"<ipython-input-9-58751ca15d31>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    https://www.youtube.com/watch?v=2FmcHiLCwTU\u001b[0m\n\u001b[1;37m           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"]}],"source":"Quick Tensorflow basics review: https://www.youtube.com/watch?v=2FmcHiLCwTU"},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":"import tensorflow as tf"},{"cell_type":"markdown","metadata":{},"source":"## Tensores\n\nLa unidad básica de datos en TensorFlow es el tensor. Un tensor es un conjunto de valores primitivos en forma de array con cualquier número de dimensiones. El rango de un tensor es su número de dimensiones, a continuación podemos ver cómo definir en TensorFlow algunos ejemplos."},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":"import numpy as np\nimport tensorflow as tf\n\nt1 = 3 # un tensor de rango 0; escalar con dimension []\nt2 = [1., 2., 3.] # un tensor de rango 1; vector con dimension [3]\nt3 = [[1., 2., 3.], [4., 5., 6.]] # un tensor de rango 2; matriz con dimension [2, 3]\nt4 = [[[1., 2., 3.]], [[7., 8., 9.]]] # un tensor de rango tres con dimensión [2, 1, 3]"},{"cell_type":"markdown","metadata":{},"source":"## El grafo computacional\n\nEl núcleo de TensorFlow se compone de dos secciones:\n\n- Construcción del grafo computacional\n- Ejecucción del grafo computacional\n\nUn grafo computacional es una serie de operaciones de TensorFlow que está compuesta de nodos. Vamos a comenzar construyendo un grafo computacional simple. Cada nodo recibe como entrada cero o más tensores produce un tensor como salida. Las constantes son un tipo de nodo. Como cualquier otra constante, un nodo que contiene una constante no tiene entradas, y produce una salida que contiene el valor que guarda internamente. Podemos crear dos tensores (coma flotante) _node1_ y _node2_ de la siguiente forma:"},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"Tensor(\"Const:0\", shape=(), dtype=float32) Tensor(\"Const_1:0\", shape=(), dtype=float32)\n"}],"source":"node1 = tf.constant(3.0, dtype=tf.float32)\nnode2 = tf.constant(4.0) # tipo tf.float32 por defecto\nprint(node1, node2)"},{"cell_type":"markdown","metadata":{},"source":"<font color='blue'> mi nota: un node de constante no tiene salida, es la constante </font>"},{"cell_type":"markdown","metadata":{},"source":"Si nos fijamos, la salida de la función _print_ no ha mostrado los valores 3.0 y 4.0 que cabría esperar. Esto es porque las variables _node1_ y _node2_ son nodos que, cuando son evaluados, producen 3.0 y 4.0 respectivamente. Para evaluar los nodos, tenemos que ejecutar el grafo computacional dentro de una sesión. Una sesión encapsula el control y estado de una ejecución TensorFlow.\n\nEl código que vemos a continuación crea una sesión e invoca su ejecución para evaluar las variables _node1_ y _node2_:"},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"[3.0, 4.0]\n"}],"source":"sess = tf.Session()\nprint(sess.run([node1, node2]))"},{"cell_type":"markdown","metadata":{},"source":"Como podemos ver, ahora la función print sí ha impreso los valores 3.0 y 4.0 que esperabamos. \n\nPodemos también realizar cómputos más elaborados combinando nodos Tensor con operaciones (las operaciones también son nodos en el entorno TensorFlow). Por ejemplo, podemos sumar dos nodos constante y producir un nuevo grafo de la siguiente forma:"},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":"a = tf.placeholder(tf.float32)\nb = tf.placeholder(tf.float32)\nadder_node = a + b  # + es una forma más rápida de utilizar tf.add(a, b)"},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"node3: Tensor(\"Add_1:0\", shape=(), dtype=float32)\nsess.run(node3): 7.0\n"}],"source":"node3 = tf.add(node1, node2)\nprint(\"node3:\", node3)\nprint(\"sess.run(node3):\", sess.run(node3))"},{"cell_type":"markdown","metadata":{},"source":"Lo que acabamos de definir es más o menos una función en el que definimos dos parámetros de entrada (_a_ y _b_) y una operación (_+_). Para evaluar este grafo tenemos que dar primero un valor a los _placeholders_. Podemos evaluar este grafo con una o varias entradas de la siguiente forma:"},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"7.5\n[3. 7.]\n"}],"source":"print(sess.run(adder_node, {a: 3, b: 4.5}))\nprint(sess.run(adder_node, {a: [1, 3], b: [2, 4]}))"},{"cell_type":"markdown","metadata":{},"source":"Como podemos ver, el grafo que acabamos de crear puede utilizarse con tensores de distinto rango y realiza la suma de estas entradas. El grafo tiene esta forma:\n<img src=\"S1_02.png\" style=\"height: 200px\">\n\nDe esta forma, podemos continuar con grafos más complejos añadiendo más operaciones, por ejemplo:"},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"22.5\n"}],"source":"add_and_triple = adder_node * 3.\nprint(sess.run(add_and_triple, {a: 3, b: 4.5}))"},{"cell_type":"markdown","metadata":{},"source":"## Variables\n\nEn Machine Learning, típicamente queremos un modelo que pueda recibir cualquier numero de entradas, como el que acabamos de crear. Sin embargo, para poder hacer un modelo entrenable, necesitamos poder modificar el grafo de forma que las mismas entradas puedan producir nuevas salidas. Para ello, tenemos que utilizar _Variables_ TensorFlow. Estas variables nos permiten añadir parámetros entrenables a un grafo. Se definen con un tipo y un valor inicial:"},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":"W = tf.Variable([.3], dtype=tf.float32)\nb = tf.Variable([-.3], dtype=tf.float32)\nx = tf.placeholder(tf.float32)\nlinear_model = W*x + b"},{"cell_type":"markdown","metadata":{},"source":"Las constantes se inicializan de forma automática cuando las definimos utilizando tf.constant, y su valor nunca cambia. Sin embargo, las variables no se inicializan al crear la variable. Para inicializar todas las variables en TensorFlow, tenemos que utilizar de forma explícita la siguiente función:"},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":"init = tf.global_variables_initializer()\nsess.run(init)"},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"data":{"text/plain":"array([0.3], dtype=float32)"},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":"sess.run(W)"},{"cell_type":"markdown","metadata":{},"source":"De esta forma, _init_ se encargará de inicializar todas las variables globales una vez que es llamado dentro de una sesión TensorFlow.\n\nComo _x_ es un _placeholder_, podemos evaluar _linear_model_ para distintos valores de _x_ simultánemaente de la siguiente forma:"},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"data":{"text/plain":"array([0.        , 0.3       , 0.6       , 0.90000004], dtype=float32)"},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":"sess.run(linear_model, {x: [1, 2, 3, 4]})"},{"cell_type":"markdown","metadata":{},"source":"## Evaluación del modelo\n\nYa hemos creado un modelo, pero aún no tenemos ninguna forma de evaluarlo. Para evaluar un modelo en datos de entremiento, necesitamos otro placeholder que provea nuestras etiquetas o _ground_truth_ con los valores esperados, además de una función de coste.\n\nLa función de coste mide la desviación existente entre los valores predichos por el modelo y los valores deseados. Vamos a comenzar utilizando una función de coste típica en regresión lineal, que consiste en la suma de los cuadrados de la diferencia entre ambos valores. Traducido al entorno TensorFlow esto se hace de la siguiente forma:"},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":"y = tf.placeholder(dtype=tf.float32)\nsquared_deltas = tf.square(linear_model - y)\nloss = tf.reduce_sum(squared_deltas)"},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"23.66\n"}],"source":"print(sess.run(loss, {x: [1, 2, 3, 4], y: [0, -1, -2, -3]}))"},{"cell_type":"markdown","metadata":{},"source":"Donde:\n- _linear_\\__model - y_ es la diferencia entre los valores predichos y los valores deseados\n- _tf.square_ realiza los cuadrados de dichos valores\n- _tf.reduce_\\__sum_ realiza la suma de todos los cuadrados, creando un escalar que podemos ver como el error de todos los ejemplos.\n\nPodríamos mejorar nuestro modelo asignando de forma manual los valores óptimos a _W_ y _b_ (-1 y 1 respectivamente). Una variable se inicializa con el valor preasignado cuando fue definida pero puede cambiarse utilizando funciones como _tf.assign_. Esto se hace de la sigueinte forma:"},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"0.0\n"}],"source":"fixW = tf.assign(W, [-1.])\nfixb = tf.assign(b, [1.])\nsess.run([fixW, fixb])\nprint(sess.run(loss, {x: [1, 2, 3, 4], y: [0, -1, -2, -3]}))"},{"cell_type":"markdown","metadata":{},"source":"Como podemos ver, una vez hemos asignado los valores óptimos a _W_ y _b_ obtenemos un error 0. Aun así, nuestro objetivo cuando enfrentamos un problema de Machine Learning es encontrar estos valores de forma automática.\n\n## Machine Learning en TensorFlow\n\nTensorFlow tiene distintos optimizadores que van cambiando poco a poco el valor de las variables para minimzar la función de coste. El optimizador más simple (y en el que están basados casi todos los demás) es el descenso de gradiente. Este optimizador modifica cada variable en función de la derivada parcial de la función de coste con respecto de dicha variable. Generalmente, calcular las derivadas parciales es complicado, tedioso e induce a muchos errores. Por suerte, TensorFlow es capaz de realizar todos los cálculos de forma automática cuando invocamos un optimizador. El código sería de la siguiente forma:"},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[array([0.3], dtype=float32), array([-0.3], dtype=float32)]\n","[array([-0.9999969], dtype=float32), array([0.9999908], dtype=float32)]\n"]}],"source":"optimizer = tf.train.GradientDescentOptimizer(0.01)\ntrain = optimizer.minimize(loss)\nsess.run(init) # reset values to incorrect defaults.\nprint(sess.run([W, b]))\nfor i in range(1000):\n  sess.run(train, {x: [1, 2, 3, 4], y: [0, -1, -2, -3]})\n\nprint(sess.run([W, b]))"},{"cell_type":"markdown","metadata":{},"source":"Enhorabuena! Ahora sí que hemos hecho Machine Learning. \n\nA modo de resúmen, este es el código que se necesita para el modelo de regresor lineal que acabamos de entrenar:"},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["W: [-0.9999969] b: [0.9999908] loss: 5.6999738e-11\n"]}],"source":"import tensorflow as tf\n\n# Model parameters\nW = tf.Variable([.3], dtype=tf.float32)\nb = tf.Variable([-.3], dtype=tf.float32)\n# Model input and output\nx = tf.placeholder(tf.float32)\nlinear_model = W*x + b\ny = tf.placeholder(tf.float32)\n\n# loss\nloss = tf.reduce_sum(tf.square(linear_model - y)) # sum of the squares\n# optimizer\noptimizer = tf.train.GradientDescentOptimizer(0.01)\ntrain = optimizer.minimize(loss)\n\n# training data\nx_train = [1, 2, 3, 4]\ny_train = [0, -1, -2, -3]\n# training loop\ninit = tf.global_variables_initializer()\nsess = tf.Session()\nsess.run(init) # reset values to wrong\nfor i in range(1000):\n  sess.run(train, {x: x_train, y: y_train})\n\n# evaluate training accuracy\ncurr_W, curr_b, curr_loss = sess.run([W, b, loss], {x: x_train, y: y_train})\nprint(\"W: %s b: %s loss: %s\"%(curr_W, curr_b, curr_loss))"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":""}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3}},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3}}