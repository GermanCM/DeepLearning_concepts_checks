{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"mioti.png\" style=\"height: 100px\">\n",
    "<center style=\"color:#888\">Módulo Data Science in IoT<br/>Asignatura Deep Learning</center>\n",
    "# Worksheet S2: Redes Neuronales Convolucionales (CNNs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### https://www.youtube.com/watch?v=2-Ol7ZB0MmU\n",
    "#### https://www.youtube.com/watch?v=FTr3n7uBIuE\n",
    "#### https://github.com/llSourcell/Convolutional_neural_network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Lección Siraj\n",
    "http://localhost:8889/notebooks/Documents/DataScience/Convolutional_neural_network-master/Convolutional_neural_network-master/convolutional_network_tutorial.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objetivos\n",
    "\n",
    "El objetivo de este worksheet es comprender las características principales de las redes convolucionales así como su implementación en TensorFlow\n",
    "\n",
    "## Introducción\n",
    "\n",
    "Las redes neuronales convolucionales están presentes en la gran mayoria de algoritmos del estado del arte en Machine Learning hoy en día. Son una tipo de red neuronal donde las neuronas corresponden a campos receptivos, de forma muy parecida a las neuronas en la corteza visual primaria de un cerebro humano. Desde un punto de vista técnico, son una variación de las redes neuronales profundas (perceptrón multicapa), donde las neuronas se aplican a matrices bidimensionales. Por este motivo, son tremendamente efectivas en tareas de visión artificial, como la clasificación y/o segmentación de imagenes o videos.\n",
    "\n",
    "En la actualidad, las redes neuronales convolucionales pueden trabajar con arrays de 1D (señales o secuencias), 2D (imágenes) o 3D (video). Son el estado del arte en innumerables problemas como el reconocimiento de objetos o la transcripción de escritura manuscrita.\n",
    "\n",
    "\n",
    "## Partes de una Red Neuronal Convolucional\n",
    "\n",
    "A continuación vamos a desgranar las distintas partes de una red neuronal convolucional para entender su funcionamiento.\n",
    "\n",
    "En primer lugar, debemos saber que a lo que llamamos una capa de una CNN está formado por dos sub-capas que son la sub-capa convolucional y la sub-capa de pooling o subsampling.\n",
    "\n",
    "### Capa convolucional\n",
    "\n",
    "La capa convolucional puede entenderse como un extractor de características. La capa convolucional aplica un número de filtros de convolución a la 'imagen' de entrada, creando una serie de mapas de carácteristicas aplicando filtros. Una característica que es muy importante comprender es que cada mapa de características, está formado aplicando un mismo filtro compartido a distintas partes de la imagen de entrada. \n",
    "\n",
    "<img src=\"cnn_01.png\" style=\"height: 400px\">\n",
    "\n",
    "Como podemos ver en la imagen, la sub-capa convolucional está formada por:\n",
    "\n",
    "- Una entrada (para nuestro ejemplo será una imagen)\n",
    "- Campo receptivo, es el tamaño de la entrada que se procesara para extraer una característica\n",
    "- Matriz de pesos, contiene todos los filtros que se van a utilizar en esta capa para extraer características\n",
    "\n",
    "Suponiendo que nuestra capa convolucional tiene un sólo filtro, lo que hacemos es ir recorriendo nuestra imagen de entrada poco a poco, de forma que extraeremos un punto de nuestro feature map mediante la aplicación de una función no lineal a la convolución de nuestro campo receptivo con nuestro filtro, produciendo un sólo valor en el mapa de características por cada sub-región de la imagen de entrada a la que aplicamos el filtro.\n",
    "\n",
    "Como vemos en las imagenes siguientes, lo que vamos haciendo es símplemente mover este campo receptivo poco a poco por toda la imagen de entrada hasta que la hemos recorrido por completo, obteniendo un mapa de características.\n",
    "\n",
    "<img src=\"cnn_02.png\" style=\"height: 400px\">\n",
    "<img src=\"cnn_03.png\" style=\"height: 400px\">\n",
    "\n",
    "En la práctica, nuestra sub-capa convolucional tendrá varios filtros, por lo que este proceso se repite para cada uno de ellos, obteniendo así varios mapas de características.\n",
    "\n",
    "<img src=\"cnn_04.png\" style=\"height: 400px\">\n",
    "\n",
    "\n",
    "### Capa de agrupación (pooling)\n",
    "\n",
    "A cada convolucional le suele seguir una capa pooling, que se encarga de reducir la dimensionalidad de la imagen extraída por la capa convolucional o mapa de características. Esto se hace para reducir el tiempo de procesado necesario y para obtener cierta invariabilidad a pequeñas rotaciones o traslaciones. \n",
    "\n",
    "Esta capa realiza una operación recorriendo poco a poco la imagen de entrada (que es la salida de la capa convolucional). De forma similar a lo que hacía la capa anterior, irá mirando a un campo receptivo y realizando una operación sencilla, que suele ser una media de todos los valores o una selección del máximo. Una posibilidad sería un campo receptivo de 2x2 pixels y función max, con esta configuración esta capa iría procesando la imagen de entrada en regiones de 2x2 y seleccionando el máximo de cada una de estas regiones.\n",
    "\n",
    "<img src=\"cnn_05.png\" style=\"height: 400px\">\n",
    "\n",
    "\n",
    "La arquitectura más típica de una red convolucional consiste en una serie de módulos convolucionales que actúan como extractor de características. Cada uno de estos módulos está formado por una capa convolucional seguido de una capa pooling. A continuación, se utiliza una o varias capas perceptron, que llamaremos Dense, que realiza la clasificación final. En un problema de clasificación multiclase la última capa será de tipo Dense y tendrá tantas neuronas como clases tenga el problema, y la función de activación será de tipo softmax.\n",
    "\n",
    "La función de activación softmax fuerza a que la suma de todas las salidas sea 1, de forma que las salidas puedan interpretarse como la probabilidad de la imagen de entrada de pertenecer a cada una de esas clases.\n",
    "\n",
    "En la siguiente imagen podemos ver una posible estructura para un problema de reconocimiento de idioma, cuya entrada es un espectrograma y hay 8 posibles idiomas.\n",
    "\n",
    "<img src=\"cnn_06.png\" style=\"height: 400px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*MI NOTA: en general, el número de neuronas de la capa de entrada será igual a el numero de features (dimensión que será largo x ancho)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*MI NOTA: por ejemplo la mapa de aristas sería como una matriz de 0 y 1 donde cada pixel es parte o no de una arista (de esto va el tema de filtros creo)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*MI NOTA: el número de filtros lo especificamos nosotros (por ensayo-error, esto es \"oculto\" en cierto modo)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*MI NOTA: la última dibujada en rojo es aplicando la función softmax*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNNs en TensorFlow\n",
    "\n",
    "Ahora vamos a ver cómo se definen estas capas en TensorFlow, como siempre, comenzamos importando los paquetes que vamos a necesitar.\n",
    "\n",
    "Además, importaremos los datos que vamos a utilizar, correspondientes a MNIST, definirmeos también algunas variables de los datos de entrada e inicializaremos los placeholder que almacenaran nuestros datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-14659c3e1854>:6: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "\n",
    "# Import MNIST data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True) \n",
    "#one_hot es un vector de todo ceros salvo un 1; vector tamaño 10 que indica qué cifra es (en la posición correcta será 1)\n",
    "\n",
    "# Parameters\n",
    "learning_rate = 0.001\n",
    "training_iters = 10000\n",
    "batch_size = 128 #cada ctos datos individuales doy un paso (al paso de learning rate)\n",
    "display_step = 10 \n",
    "\n",
    "# Network Parameters\n",
    "n_input = 784   # MNIST data input (img shape: 28*28)\n",
    "n_classes = 10  # MNIST total classes (0-9 digits)\n",
    "\n",
    "# tf Graph input\n",
    "x = tf.placeholder(tf.float32, [None, n_input])\n",
    "y = tf.placeholder(tf.float32, [None, n_classes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación vamos a ver cada una de estas capas:\n",
    "\n",
    "### Capa de entrada\n",
    "\n",
    "En primer lugar, necesitamos modificar el formato de entrada de los datos, ya que las capas convolucionales esperan tensores de 4 dimensiones:  #muestras x ancho x alto x #canales\n",
    "\n",
    "En nuestro caso, vamos a realizar la redefinición sobre el propio placeholder que contiene los datos. Nuestras imágenes son de tamaño 28x28 y al ser monocromáticas el número de canales será 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_reshaped = tf.reshape(x, shape=[-1, 28, 28, 1])  #shape --> batch, ancho, alto, canales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver, la primera dimensión, el número de muestras, la hemos definido con valor -1, esto indica a TensorFlow que esta dimensión debe ser calculada de forma dinámica en tiempo de ejecución, ya que aún no sabemos cuantas muestras tendremos.\n",
    "\n",
    "### Convolucional\n",
    "\n",
    "Utilizaremos la función conv2d(). Crea una capa convolucional para entradas de 2 dimensiones. \n",
    "\n",
    "Recibe como entrada:\n",
    "- inputs, que es la entrada a la capa\n",
    "- filters, que es el número de filtros que se va a utilizar\n",
    "- kenel_size, que es el tamaño de los filtros\n",
    "- strides, que es el paso que se va a utilizar entre campo receptivo y campo receptivo\n",
    "- padding, que es para el relleno a la entrada, nosotros utilizaremos ¨SAME¨\n",
    "- activation, que es la funcion que se va a aplicar después de la convolución\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = tf.reshape(x, [-1, 28, 28, 1])\n",
    "\n",
    "conv1 = tf.layers.conv2d(\n",
    "    inputs=input_layer,\n",
    "    filters=32, #num filtros\n",
    "    kernel_size=[5,5],  #tamaño del filtro\n",
    "    strides=(1, 1), #cada cuántos pixeles se mueve (creo)\n",
    "    activation=tf.nn.relu,\n",
    ")\n",
    "\n",
    "# conv1 = tf.layers.conv2d(input_layer, 32, 5, activation=tf.nn.relu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver, conv2d espera un tensor de 4 dimensiones: #muestras, ancho, alto, #canales\n",
    "\n",
    "La salida será otro tensor de 4 dimensiones.\n",
    "\n",
    "### Pooling\n",
    "\n",
    "Utilizaremos la función max_pooling2d(). Esta función realiza la función max sobre el campo receptivo que le indiquemos, en nuestro caso utilizaremos un filtro de tamaño 2x2 con un paso entre muestreos de 2.\n",
    "\n",
    "Recibe como entrada:\n",
    "- inputs, que es la entrada a la capa\n",
    "- pool_size, que es el tamaño del campo receptivo\n",
    "- strides, que es el paso al hacer el barrido de la imagen de entrada\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense\n",
    "\n",
    "Finalmente, utilizaremos una capa de tipo Dense. Para ello primero vamos a convertir nuestra imagen 2D (la salida de pool1) en un vector, para ello utilizaremos la función flatten()\n",
    "\n",
    "A continuacion utilizamos la función tf.layers.dense(), que recibe como entrada el número de unidades y la función de activación, la salida será del tamaño del número de unidades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool1_flat = tf.contrib.layers.flatten(pool1)  #vectorizamos la entrada (vector de nx1)\n",
    "\n",
    "dense = tf.layers.dense(inputs=pool1_flat, units=512, activation=tf.nn.relu)  #units-> num de neuronas, esto es capa oculta y pto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* mi nota: dense, feedforward, DNN, recurrente, etc... tipos de capas*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Capa de salida\n",
    "\n",
    "Finalmente, necesitamos una capa de salida, que será de tipo Dense y tendrá tantas neuronas como clases tiene nuestro problema.\n",
    "\n",
    "La función de activación será de tipo softmax, de esta forma la salida pueda interpretarse como probabilidades de pertenecer a cada una de las clases.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = tf.layers.dense(inputs=dense, units=n_classes, activation=tf.nn.softmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Englobando la creación del modelo en una función por simplicidad:\n",
    "\n",
    "Previamente hemos visto qué instrucciones necesitamos para crear cada una de las capas que necesitaremos en nuestro modelo. A continuación, vamos a unir todos estos comandos en una sola función para poder llamarla cuando creemos el grafo computaciónal de forma más simple y ordenada. Esto nos permite también crear distintos modelos, uno en cada función, y poder invocar uno u otro en tiempo de ejecución:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_net(x, n_classes):\n",
    "\n",
    "    # MNIST data input is a 1-D vector of 784 features (28*28 pixels)\n",
    "    # Reshape to match picture format [Height x Width x Channel]\n",
    "    # Tensor input become 4-D: [Batch Size, Height, Width, Channel]\n",
    "    x = tf.reshape(x, shape=[-1, 28, 28, 1])\n",
    "\n",
    "    # Convolution Layer with 32 filters and a kernel size of 5\n",
    "    conv1 = tf.layers.conv2d(x, 32, 5, activation=tf.nn.relu)\n",
    "    # Max Pooling (down-sampling) with strides of 2 and kernel size of 2\n",
    "    conv1 = tf.layers.max_pooling2d(conv1, 2, 2)\n",
    "\n",
    "    # Flatten the data to a 1-D vector for the fully connected layer\n",
    "    fc1 = tf.contrib.layers.flatten(conv1)\n",
    "\n",
    "    # Fully connected layer (in tf contrib folder for now)\n",
    "    fc1 = tf.layers.dense(fc1, 1024)  #aquí por ej. en lugar de 512 hemos puesto 1024 units\n",
    "        \n",
    "    # Output layer, class prediction\n",
    "    out = tf.layers.dense(fc1, n_classes)\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construyendo el grafo computacional\n",
    "\n",
    "Una vez que tenemos nuestro modelo definido en una función, podemos pasar a la construcción del grafo computacional completo, que en este caso se compone del modelo, de la función de coste a minimizar, del optimizador, y de las funciones necesarias para evaluar el modelo.\n",
    "\n",
    "Pred contendrá nuestro modelo, que al recibir los datos como entrada proporciona la probabilidad de pertenencia a cada una de las clases.\n",
    "\n",
    "Cost será nuestra función de coste, en este caso hemos utilizado entropía cruzada que podemos interpretarlo como una distancia entre la etiqueta y la predicción, más información en: https://en.wikipedia.org/wiki/Cross_entropy\n",
    "\n",
    "Optimizer va a ser nuestro optimizador, en este caso vamos a utilizar Adam, se utiliza de la misma forma que el descenso por gradiente y es una versión mejorada de este.\n",
    "\n",
    "Correct pred tomará un valor de 1 cuando la predicción sea correcta y un valor de 0 cuando sea incorrecta.\n",
    "\n",
    "Accuracy será el porcentaje de aciertos de la red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct model\n",
    "pred = conv_net(x, n_classes)\n",
    "\n",
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=pred, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)  #aquí Adam, pero podría ser SGD por ej\n",
    "\n",
    "# Evaluate model\n",
    "correct_pred = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejecutando el grafo computacional y evaluando el resultado\n",
    "\n",
    "Por último, inicializaremos las variables globales, y definiremos una sesión. Dentro de esta sesión realizaremos tantas iteraciones como hayamos definido al principio de nuestro código y en cada una de estas iteraciones ejecutaremos nuestro modelo con el optimizador seleccionado.\n",
    "\n",
    "Como podmeos ver en el código, los pasos son los mismos que seguimos con el regresor lineal, con las siguientes modificaciones:\n",
    "\n",
    "- El número de iteraciones no es fijo, depende del tamaño del batch.\n",
    "- Hemos añadido una función para imprimir por pantalla el rendimiento actual cada display_step pasos\n",
    "\n",
    "En la parte final, ejecutamos el grafo computacional ya entrenado con los datos de test y mostramos el resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1280, Minibatch Loss= 0.620316, Training Accuracy= 0.86719\n",
      "Iter 2560, Minibatch Loss= 0.279208, Training Accuracy= 0.91406\n",
      "Iter 3840, Minibatch Loss= 0.218876, Training Accuracy= 0.91406\n",
      "Iter 5120, Minibatch Loss= 0.289511, Training Accuracy= 0.92969\n",
      "Iter 6400, Minibatch Loss= 0.182966, Training Accuracy= 0.94531\n",
      "Iter 7680, Minibatch Loss= 0.205121, Training Accuracy= 0.94531\n",
      "Iter 8960, Minibatch Loss= 0.162494, Training Accuracy= 0.95312\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.96484375\n"
     ]
    }
   ],
   "source": [
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    step = 1\n",
    "    # Keep training until reach max iterations\n",
    "    while step * batch_size < training_iters:\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        # Run optimization op (backprop)\n",
    "        sess.run(optimizer, feed_dict={x: batch_x, y: batch_y})\n",
    "        if step % display_step == 0:\n",
    "            # Calculate batch loss and accuracy\n",
    "            loss, acc = sess.run([cost, accuracy], feed_dict={x: batch_x,\n",
    "                                                              y: batch_y,\n",
    "                                                              })\n",
    "            print(\"Iter \" + str(step*batch_size) + \", Minibatch Loss= \" + \\\n",
    "                  \"{:.6f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                  \"{:.5f}\".format(acc))\n",
    "        step += 1\n",
    "    print(\"Optimization Finished!\")\n",
    "\n",
    "    # Calculate accuracy for 256 mnist test images\n",
    "    print(\"Testing Accuracy:\", \\\n",
    "        sess.run(accuracy, feed_dict={x: mnist.test.images[:256],\n",
    "                                      y: mnist.test.labels[:256],\n",
    "                                      }))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resumen del código utilizado\n",
    "\n",
    "A modo de resumen, se muestra a continuación el código que se ha utilizado, y que será el punto de partida para el challenge de esta clase:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
      "[[0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]]\n",
      "Iter 1280, Minibatch Loss= 0.634154, Training Accuracy= 0.80469\n",
      "[[0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]]\n",
      "Iter 2560, Minibatch Loss= 0.537672, Training Accuracy= 0.85938\n",
      "[[0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]]\n",
      "Iter 3840, Minibatch Loss= 0.250504, Training Accuracy= 0.91406\n",
      "[[0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]]\n",
      "Iter 5120, Minibatch Loss= 0.220286, Training Accuracy= 0.92969\n",
      "[[0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]]\n",
      "Iter 6400, Minibatch Loss= 0.166756, Training Accuracy= 0.95312\n",
      "[[0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]]\n",
      "Iter 7680, Minibatch Loss= 0.117198, Training Accuracy= 0.95312\n",
      "[[0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]]\n",
      "Iter 8960, Minibatch Loss= 0.112985, Training Accuracy= 0.96094\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.9765625\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "\n",
    "# Import MNIST data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)\n",
    "\n",
    "# Parameters\n",
    "learning_rate = 0.001\n",
    "training_iters = 10000\n",
    "batch_size = 128\n",
    "display_step = 10\n",
    "\n",
    "# Network Parameters\n",
    "n_input = 784   # MNIST data input (img shape: 28*28)\n",
    "n_classes = 10  # MNIST total classes (0-9 digits)\n",
    "\n",
    "# tf Graph input\n",
    "x = tf.placeholder(tf.float32, [None, n_input])\n",
    "y = tf.placeholder(tf.float32, [None, n_classes])\n",
    "\n",
    "def conv_net(x, n_classes):\n",
    "\n",
    "    # MNIST data input is a 1-D vector of 784 features (28*28 pixels)\n",
    "    # Reshape to match picture format [Height x Width x Channel]\n",
    "    # Tensor input become 4-D: [Batch Size, Height, Width, Channel]\n",
    "    x = tf.reshape(x, shape=[-1, 28, 28, 1])\n",
    "\n",
    "    # Convolution Layer with 32 filters and a kernel size of 5\n",
    "    conv1 = tf.layers.conv2d(x, 32, 5, activation=tf.nn.relu)\n",
    "    # Max Pooling (down-sampling) with strides of 2 and kernel size of 2\n",
    "    conv1 = tf.layers.max_pooling2d(conv1, 2, 2)\n",
    "\n",
    "    # Flatten the data to a 1-D vector for the fully connected layer\n",
    "    fc1 = tf.contrib.layers.flatten(conv1)\n",
    "\n",
    "    # Fully connected layer (in tf contrib folder for now)\n",
    "    fc1 = tf.layers.dense(fc1, 1024)\n",
    "        \n",
    "    # Output layer, class prediction\n",
    "    out = tf.layers.dense(fc1, n_classes)\n",
    "    \n",
    "    return out\n",
    "\n",
    "# Construct model\n",
    "pred = conv_net(x, n_classes)\n",
    "\n",
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# Evaluate model\n",
    "correct_pred = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    step = 1\n",
    "    # Keep training until reach max iterations\n",
    "    while step * batch_size < training_iters:\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        # Run optimization op (backprop)\n",
    "        sess.run(optimizer, feed_dict={x: batch_x, y: batch_y})\n",
    "        if step % display_step == 0:\n",
    "            # Calculate batch loss and accuracy\n",
    "            loss, acc = sess.run([cost, accuracy], feed_dict={x: batch_x,\n",
    "                                                              y: batch_y,\n",
    "                                                              })\n",
    "            \n",
    "            print(\"Iter \" + str(step*batch_size) + \", Minibatch Loss= \" + \\\n",
    "                  \"{:.6f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                  \"{:.5f}\".format(acc))\n",
    "        step += 1\n",
    "    print(\"Optimization Finished!\")\n",
    "\n",
    "    # Calculate accuracy for 256 mnist test images\n",
    "    print(\"Testing Accuracy:\", \\\n",
    "        sess.run(accuracy, feed_dict={x: mnist.test.images[:256],\n",
    "                                      y: mnist.test.labels[:256],\n",
    "                                      }))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
